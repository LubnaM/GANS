{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1keqrM2aW3QU4A7lkBPA0Zb0EJlooaQ68",
      "authorship_tag": "ABX9TyOFj1gjGwTHl6MUAEtiSwHU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LubnaM/GANS/blob/main/GANs_Basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade ipywidgets\n",
        "!jupyter nbextension enable --py widgetsnbextension"
      ],
      "metadata": {
        "id": "PD0SROdsA-GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyRzSLvEnXAN"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install tensorflow ipywidgets tensorflow-datasets tensorflow-gpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Bringing tensorflow fashion_mnist dataset\n",
        "import tensorflow_datasets as tfds\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "ds=tfds.load('fashion_mnist', split='train')"
      ],
      "metadata": {
        "id": "dHvbyQC6oq5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.as_numpy_iterator().next()['image'] #replace image by label to view the label"
      ],
      "metadata": {
        "id": "CK132cyOq3_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "dataiterator=ds.as_numpy_iterator()\n"
      ],
      "metadata": {
        "id": "ROMIvjsmr5Uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch=dataiterator.next() # in batch, image by image will be called if we call .next()\n"
      ],
      "metadata": {
        "id": "fwHTa451sQLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualization of the dataset\n",
        "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
        "for idx in range(4):\n",
        "    sample=dataiterator.next() #sample here have 2 features image and label\n",
        "    # This to plot image in to a sub plot, squeeze is to remove the 3rd dimention\n",
        "    ax[idx].imshow(np.squeeze(sample['image']))\n",
        "    # add image label as a title\n",
        "    ax[idx].title.set_text(sample['label'])"
      ],
      "metadata": {
        "id": "rY6X6uBawdTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "' Dataset preprocessing '\n",
        "# Scaling the features to be between 0 and 1, instead of 1 to 255 ...\n",
        "def scale_images(data):\n",
        "  image=data['image']\n",
        "  return image/255"
      ],
      "metadata": {
        "id": "6wYrc7KbzCGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'--- Build the neural network ---'\n",
        "#Conditional GAN is what we need to implement, we need to pass what type of text we want to generate. See this utube\n",
        "#A data pipeline for building a tensorflow: cache > shuffle > batch > prefetch\n",
        "ds=tfds.load('fashion_mnist', split='train')\n",
        "#scale the image thru image function\n",
        "ds=ds.map(scale_images)\n",
        "#store intermediate results in memory or on disk. This can significantly speed up subsequent operations by avoiding the need to recompute results\n",
        "ds=ds.cache()\n",
        "ds=ds.shuffle(60000)\n",
        "#Batch in to 128 images samples\n",
        "ds=ds.batch(128)\n",
        "#Prefetch reduces the bottlenecking\n",
        "ds=ds.prefetch(64)\n",
        "\n",
        "ds.as_numpy_iterator().next().shape\n"
      ],
      "metadata": {
        "id": "1MNYrgfM9iVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "' now  generator will try to generate an image fashion, and discriminator will try to spot the fake image'\n",
        "#Sequential api for the generator and discriminator\n",
        "from tensorflow.keras.models import Sequential\n",
        "#bring the layers for the neuralnetwork. LeakyRely\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Reshape, LeakyReLU, UpSampling2D, BatchNormalization\n"
      ],
      "metadata": {
        "id": "bbY-SQeHDkGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator():\n",
        "  model=Sequential()\n",
        "  #what number of input to take\n",
        "  #128 passed to generator of spatial latent dimentions 7 X 7 X128 hidden layer\n",
        "  'takes in random value, and reshape it by 7*7*128, which is a begining of a generated image'\n",
        "  model.add(Dense(7*7*128, input_dim=128)) # For generator this is a random input of 128 vector size, which we will use it to generate the image randomly.`\n",
        "  # After a series of convolutional and pooling layers, you might end up with an output that has the shape of (7, 7, 128).\n",
        "  # You would then flatten this output (which has 7 * 7 * 128 = 6272 elements) and pass it to a dense layer to combine these features into higher-level representations.\n",
        "  model.add(LeakyReLU(0.2)) # to cater for non linearity\n",
        "  model.add(Reshape((7,7,128))) # reshape will take a dense of output of 6272 and convert is in to a begining of an image\n",
        "\n",
        "  'upsampling block1'\n",
        "  model.add(UpSampling2D()) #\n",
        "  model.add(Conv2D(128, kernel_size=5, padding='same'))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "\n",
        "  'upsampling block2'\n",
        "  model.add(UpSampling2D()) #\n",
        "  model.add(Conv2D(128, kernel_size=5, padding='same'))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "\n",
        "  'Conv block1'\n",
        "  model.add(Conv2D(128, kernel_size=4, padding='same'))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "\n",
        "  'Conv block2'\n",
        "  model.add(Conv2D(128, kernel_size=4, padding='same'))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "\n",
        "  'conv layer to get 1 output channel'\n",
        "  model.add(Conv2D(1, kernel_size=4, padding='same', activation='sigmoid'))\n",
        "\n",
        "  return model # only block 1 can be sufecient but adding more sofistication will allow the generator to learn\n"
      ],
      "metadata": {
        "id": "mh_UghopIZNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator=build_generator()\n",
        "generator.summary()"
      ],
      "metadata": {
        "id": "GLPIxIBOI1RO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img=generator.predict(np.random.rand(4,128,1))# 4 images\n"
      ],
      "metadata": {
        "id": "FpaNiTiRTZag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'Generate new images and test generator'\n",
        "#img\n",
        "#visualize it\n",
        "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
        "for idx, img in enumerate(img):\n",
        "    ax[idx].imshow(np.squeeze(img))\n",
        "    ax[idx].title.set_text(idx)"
      ],
      "metadata": {
        "id": "-IByKm3vOQng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WEwTBoLGQgu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'-- Build the discriminator -- '\n",
        "def build_discriminator():\n",
        "  model=Sequential()\n",
        "  #first conv block\n",
        "  model.add(Conv2D(32, kernel_size=5, input_shape=(28,28,1))) #(28*28 will be pashed in to 32  filter with shape 5*5 , codensing down the information its getting)\n",
        "  model.add(LeakyReLU(0.2)) # recomended practice when building GANs\n",
        "  model.add(Dropout(0.4)) # for regularization\n",
        "  #second conv block\n",
        "  model.add(Conv2D(64, kernel_size=5))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Dropout(0.4))\n",
        "  #second conv block\n",
        "  model.add(Conv2D(64, kernel_size=5))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Dropout(0.4))\n",
        "  #Third conv block\n",
        "  model.add(Conv2D(128, kernel_size=5))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Dropout(0.4))\n",
        "  #Fourth conv block\n",
        "  model.add(Conv2D(256, kernel_size=5))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Dropout(0.4))\n",
        "  #Flatten then pass to dense layer\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1, activation='sigmoid')) # 1 is false image, and 0 is true image.\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "Ov6T0j6jQgyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator=build_discriminator()\n"
      ],
      "metadata": {
        "id": "FuS5wDMAQ1Tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator.summary()"
      ],
      "metadata": {
        "id": "54kx5VkHR325"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test the generated images\n",
        "#discriminator.predict(img) # if 1 its a fake if less, its nearly near the truth value\n",
        "# Add a batch dimension to the image data\n",
        "discriminator.predict(np.expand_dims(img, axis=0)) # if 1 its a fake if less, its nearly near the truth value"
      ],
      "metadata": {
        "id": "Jueq64DRS_rQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "' - custom training loop to train the generator and discriminator simultanuesly -'\n",
        "#setup some losses and optimizes\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "lkCJwEWPT55l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g_opt = Adam(learning_rate=0.0001) #Generator faster\n",
        "d_opt = Adam(learning_rate=0.00001) #discriminator we dont want discriminator to go too fast than generator\n",
        "loss_fn = BinaryCrossentropy()"
      ],
      "metadata": {
        "id": "pKb5YEChT59G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.concat([tf.zeros_like(tf.random.normal((6,128))),tf.ones_like(tf.random.normal((6,128)))],axis=0) # This is  will be generating a bunch of ones in to the generator and g"
      ],
      "metadata": {
        "id": "LHyGh0PsF5rT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the basemodel class to subclass our training step\n",
        "from tensorflow.keras.models import Model\n",
        "class FashionGAN(Model):\n",
        "  def __init__(self, generator, discriminator, *args,**kwargs):\n",
        "    # pass args and kwars to base class\n",
        "    super().__init__(*args,**kwargs)\n",
        "    #create attributes for generators and disc\n",
        "    self.generator=generator\n",
        "    self.discriminator=discriminator\n",
        "\n",
        "  def compile(self,g_opt,d_opt,loss_fn,*args,**kwargs):\n",
        "    super().compile(*args,**kwargs)\n",
        "    self.g_opt=g_opt\n",
        "    self.d_opt=d_opt\n",
        "    self.loss_fn=loss_fn\n",
        "\n",
        "  def train_step(self,batch): # batch can 128 images *28 * 28 *1)\n",
        "    #get the data\n",
        "    real_images=batch\n",
        "    fake_images=self.generator(tf.random.normal((128,128,1)), training = False) # False means generator is not training at the moment its just making predictions\n",
        "\n",
        "    #Train the discriminator\n",
        "    with tf.GradientTape() as d_tape:\n",
        "      #pass the real and fake model in to the discriminator model.\n",
        "      yhat_real=self.discriminator(real_images, training=True)\n",
        "      yhat_fake=self.discriminator(fake_images, training=True)\n",
        "      yhat_realfake=tf.concat([yhat_real, yhat_fake], axis=0)\n",
        "      #create labels, this below will assign the labels below are true y_realfake , a labels\n",
        "      y_realfake=tf.concat([tf.zeros_like(yhat_real), tf.ones_like(yhat_fake)], axis=0)\n",
        "\n",
        "      #add noise to the TRUE output to speedup learning\n",
        "      noise_real = 0.15 * tf.random.uniform(tf.shape(yhat_real))\n",
        "      noise_fake = -0.15 * tf.random.uniform(tf.shape(yhat_fake))\n",
        "      y_realfake += tf.concat([noise_real, noise_fake],axis=0)\n",
        "\n",
        "      #calsulate loss\n",
        "      total_d_loss=self.loss_fn(y_realfake, yhat_realfake)\n",
        "    #apply back propagation - nnlearn\n",
        "    d_gradient=d_tape.gradient(total_d_loss, self.discriminator.trainable_variables)\n",
        "    self.d_opt.apply_gradients(zip(d_gradient, self.discriminator.trainable_variables))\n",
        "\n",
        "\n",
        "    #Train the generator\n",
        "    with tf.GradientTape() as g_tape:\n",
        "      #Generate some new images\n",
        "      gen_images = self.generator(tf.random.normal((128,128,1)), training=True)\n",
        "      #Create the predicted labels, run generator images thru discriminator\n",
        "      predicted_labels = self.discriminator(gen_images, training=False)#This will return a 1 if its fake #we dont discriminator to learn here, its just to determine the gen image is real or not.\n",
        "      #Calculate loss, Trick to training to fake out the discriminator #what it tries to do is to generate images that tries to fakeing#  #here generator loss is rewarded, here generated image are actually real images, so we reward our generator for faking out the discriminator, if the discriminator predicts that a generated image is real\n",
        "      total_g_loss = self.loss_fn(tf.zeros_like(predicted_labels), predicted_labels)\n",
        "    #Apply backprob.\n",
        "    g_gradient = g_tape.gradient(total_g_loss, self.generator.trainable_variables)\n",
        "    self.g_opt.apply_gradients(zip(g_gradient, self.generator.trainable_variables))#zip to do them both at the same time\n",
        "    return {\"d_loss\":total_d_loss, \"g_loss\":total_g_loss}\n",
        "#"
      ],
      "metadata": {
        "id": "4DpTcq9rBVRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create instance of subclass model\n",
        "fashgan=FashionGAN(generator, discriminator)\n"
      ],
      "metadata": {
        "id": "-2mnKJ4rdwgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile the model\n",
        "fashgan.compile(g_opt, d_opt, loss_fn)"
      ],
      "metadata": {
        "id": "2H0pZyv_d_hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'Build the call back'\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.preprocessing.image as array_to_img\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "os.makedirs('/content/drive/MyDrive/images', exist_ok=True)\n"
      ],
      "metadata": {
        "id": "PH5K2VdReKJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelMonitor(Callback):\n",
        "  def __init__(self, num_img=3, latent_dim=128):#just the random value u r passing to generate\n",
        "    self.num_img=num_img\n",
        "    self.latent_dim=latent_dim\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    #generate random\n",
        "    random_latent_vectors=tf.random.uniform(shape=(self.num_img, self.latent_dim,1))\n",
        "    generated_images=self.model.generator(random_latent_vectors)\n",
        "    generated_images *= 255\n",
        "    generated_images.numpy()\n",
        "    for i in range(self.num_img):\n",
        "      img = array_to_img.array_to_img(generated_images[i])\n",
        "      img.save(os.path.join('/content/drive/MyDrive/images', f'generated_img{i}_{epoch}.png'))"
      ],
      "metadata": {
        "id": "_RK9kxIHetN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'Train the model'\n",
        "hist=fashgan.fit(ds, epochs=20, callbacks=[ModelMonitor()])"
      ],
      "metadata": {
        "id": "reU0h4_mgSfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Review the performance\n",
        "#we saved out training in a variable called hist, then we can print it and see its performance\n",
        "hist.history"
      ],
      "metadata": {
        "id": "6FAOWTANUFWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.suptitle('loss')\n",
        "plt.plot(hist.history['d_loss'], label='d_loss')\n",
        "plt.plot(hist.history['g_loss'], label='g_loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#The performance might enhance if we go and train it for 2000 epocs"
      ],
      "metadata": {
        "id": "N10X318VSfI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'Test the Generator Model'\n",
        "#before loading the pretrain model, lets test that with baseline model\n",
        "\n",
        "imgs = generator.predict(tf.random.normal((16,128,1))) # generate 16 images, laten variable 128, then 1)\n",
        "imgs\n",
        "\n",
        "'''\n",
        "Another pretrained model can be downloaded from here :\n",
        "generatormodel.h5\n",
        "https://github.com/nicknochnack/GANBasics\n",
        "and to load its weights:\n",
        "generator.load_weights('generatormodel.h5')\n",
        "'''"
      ],
      "metadata": {
        "id": "DVCm9pUFVgNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(ncols=4,nrows=4, figsize=(20,20)) # changed ax to axs\n",
        "for idx, img in enumerate(imgs):\n",
        "    axs.flat[idx].imshow(np.squeeze(img)) # use flat iterator to correctly index the subplots\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QlIFyJq5WJVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MkjNVBHAbcVY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}